\chapter{Konzept}\label{ch:konzept}
Das folgende Kapitel thematisiert das Konzept, dass im Zuge der vorliegenden Arbeit entwickelt wurde, um die vorgestellte Problemstellung zu lösen. Zwischen vielen verschiedenen möglichen Ansätzen einen neuen Modus für das PSM System zu entwickeln, entschied ich mich für einen differenzbasierten Vergleich der Positions- und Rotationsrelationen. Dieser wird im ersten Abschnitt erläutert und anschließend wird der Algorithmus sprachlich, grafisch und in Pseudocode erklärt. Zum Schluss wird die Wahrscheinlichkeitsabschätzung für den Algorithmus erklärt und begründet.
\section{Ansatz}
Im vorhandenen PSM-System werden im Learner die erhaltenen Positions- und Rotationsdaten zu einem Modell zusammengefasst, dass die vorkommen aller Objekte in Relation zueinander zusammenfasst. Dieser Vorgang führt dazu, dass teilweise Zusammenhänge in den Daten betont werden, aber auch zu einem Informationsverlust da Ausreißer und mutmaßliche Fehlmessungen dadurch verloren gehen. Deshalb kann es sinnvoll sein direkt auf den gemessenen Daten zu arbeiten, um ein Ergebnis zu erhalten welches alle Daten berücksichtigt. \smallskip\\
Wir betrachten folgendes Szenario. Ein Roboter soll seine Aufgaben aufgrund von einer Szenenerkennung einschätzen und durchführen. In der Szene "Kaffee" gibt es eine volle Kaffeetasse und einen Teelöffel und seine Aufgabe ist es mit dem Löffel den Kaffee umzurühren. In seinen Referenzdaten zu der Szene war der Löffel meist direkt neben der Tasse und nur in einem Fall ein Stück weiter entfernt. Allerdings gilt jede einzelne aufgezeichnete Refernzszene auf äquivalente Weise als Beispiel für die Szene "Kaffee". Das Parametermodell würde diese Ausreißerdaten allerdings glätten und kaum berücksichtigen, sodass der Roboter die Szene selbst mit genau dem Aufbau aus den Refernzdaten möglicherweise nicht erkennen würde. Wenn man allerdings die Erkennung direkt auf den Referenzdaten basiert, erkennt die Szenenerkennung den Ausreißer auch, da sie ja eine Instanz der Szene mit diesem vergleicht, welche diesem entspricht.\smallskip\\
Abbildung \ref{img:ausreisser} verdeutlicht das genannte Szenario. Die roten Punkte stehen für die gemessenen Positionen und die grünen Pfeile stehen für die räumliche Relation zwischen den Objekten. Links sieht man, dass die meisten Messungen einen kleinen Abstand zwischen Löffel und Tasse haben, rechts ist der Ausreißer dargestellt, der möglicherweise vom alten System nicht als die gelernte Szene erkannt wird.\smallskip\\
Im differenzbasierten Modus sollen also gemessene Objekte direkt mit den Referenzdaten verglichen werden, die das System bereits gelernt hat. Der Algorithmus betrachtet alle Objekte vollvermascht, sodass er die Szenenreferenz findet, die die maximale Ähnlichkeit zu den gemessenen Objekten hat. Darauf basierend wird die Wahrscheinlichkeit abgeschätzt, dass die gemessenen Objekte die Referenzszene enthalten oder repräsentieren. Dabei stören zusätzliche Objekte die Erkennung nicht und eine Unvollständigkeit der Szene führt zu einer kleineren Wahrscheinlichkeit aber nicht zu direkter Ablehnung, da die Szene noch durch weitere Objekterkennungen vervollständigt werden könnte.
\begin{figure}
	\centering
	\includegraphics[width=15cm]{bilder/KonzeptAnsatz.pdf}
	\caption{Beispiel: Kaffeetasse - Ausrei\ss{}er in den Daten}
	\label{img:ausreisser}
\end{figure}
\section{Erkennungsalgorithmus}
Der Algorithmus wurde mit den in Ansatz genannten Annahmen und Einschränkungen entwickelt und hat zur Aufgabe zu jeder Szene die auf Vorkommen geprüft wird die Instanz der Szene in den Daten zu finden, die am dichtesten an den gemessenen Daten liegt und so die höchste Wahrscheinlichkeit aufzeigt, dass die gemessenen Daten die Szene enthalten. Nachdem die Wahrscheinlichkeit einer Szene bestimmt ist wird diese mit den anderen Szenen genau wie im bestehenden PSM-System verrechnet, sodass am Ende die Relative Wahrscheinlichkeit für alle zutestenden Szenen angegeben wird.
\subsection{Algorithmus: Beschreibung}
\begin{figure}
	\centering
	\includegraphics[width=16cm]{bilder/AlgorithmusRoh.pdf}
	\caption{Algorithmus als vereinfachtes Flussdiagramm}
	\label{img:janein}
\end{figure}
Der  Algorithmus läuft wie folgt ab. Für jedes Objekt, der zu testenden  Szene, wird überprüft ob es sich um ein Objekt handelt, welches gerade von der Objekterkennung erkannt wird. Wenn dies nicht der Fall ist, wird das Objekt übersprungen. Wenn dies allerdings der Fall ist, wird das Objekt zeitweise zu unserem Referenzobjekt und der Algorithmus führt für jede Instanz der zu testenden Szene in den Daten folgendes aus:\smallskip\\
 Es wird über alle anderen Objekte der Szeneninstanz iteriert und für jedes Objekt abgefragt, ob es ein gemessenes Objekt gibt, welches die Repräsentation für das Datenobjekt sein kann. Falls das Objekt nicht in den momentan wahrgenommenen Objekten vorkommt, ist die Szene allein aus Sicht dieses Objekts betrachtet unwahrscheinlich. Deshalb wird eine Objektwahrscheinlichkeit von 0 eingespeichert, welche aussagt, dass dieses Objekt allein die Szene als nicht auffindbar beschreibt. Wenn allerdings eine Instanz der Objekts in der Iteration gefunden wird, berechnet der Algorithmus die Positions- und Rotationsrelation zwischen den beiden Objekten aus den Daten. Genauso wird die Position und Rotationsrelation der gemessenen Objekte zueinander berechnet, welche mutmaßlich den Objekten aus der Datenbank entsprechen sollten. Nach diesen Berechnungen wird die Differenz verglichen die zwischen den beiden Paaren jeweils besteht. Dabei werden Positionsrelationen und Orientierung beziehungsweise Rotation jeweils getrennt betrachtet. Aus dem Grad der Ähnlichkeit dieser Differenzen lässt sich nun die Wahrscheinlichkeit ableiten, Objekt so vorkommt wie die Szene aufgezeichnet wurde. Somit hat man wieder eine Objektwahrscheinlichkeit.\smallskip\\
Nun werden alle Objektwahrscheinlichkeiten zu einer Szenenwahrscheinlichkeit zusammengefasst. Diese wird innerhalb der Iteration über die Szeneninstanzen maximiert. Außerdem wird dieser Maximalwert wiederum innerhalb der äußersten Schleife maximiert, welche über alle Objekte iteriert, die sowohl in der zu testenden Szene sind als auch von der Objekterkennung erkannt wurden.  Es wird also der absolute maximale Wert der Szenenwahrscheinlichkeit bestimmt, den man mit einer der Szeneninstanzen mit der beschriebenen Schleife mit jedwedem Referenzobjekt erzeugen kann. Dieser Maximalwert ist die Wahrscheinlichkeit, ob die zu testende Szene in den Gemessenen Objekten und potentiell weiteren unbekannten Objekten enthalten ist, welche von der Objekterkennung noch erkannt werden könnten.\smallskip\\
Abbildung \ref{img:janein} beschreibt den Algorithmus als vereinfachtes Flussdiagramm. Einfache Linien verdeutlichen den Programmfluss in den verschiedenen Fällen und die Flussrichtung ist stehts nach unten. Die Schleifen sind zusammengefasst damit das Diagramm übersichtlich bleibt.
\subsection{Algorithmus: Pseudocode}
\begin{figure}
	\centering
	\includegraphics[width=16cm]{bilder/PseudoCode.pdf}
	\caption{Algorithmus als PseudoCode}
	\label{img:pseudocode}
\end{figure}
Um das Algorithmuskonzept weiter zu verdeutlichen beschreibt Abbildung \ref{img:pseudocode} den Algorithmus nochmals mit Pseudocode. Damit der Code verständlich wird hier eine kurze Erklärung zu der Abbildung. Die Einrückungen wurden statt den geschweiften Klammern verwendet, die in den meisten höheren Programmiersprachen vorkommen. Die Parameter sind wie folgt definiert. Szenenmodell beschreibt das Szenenmodell, dass die vorkommenden Objekte in der zu testenden Szene beinhaltet. Der Parameter Gemessen beschreibt die Objekte die momentan erkannt werden und real oder in einer Simulation vorhanden sind. Der Parameter Daten steht für die Instanzen die zur zu testenden Szene als Referenzen gespeichert sind.\smallskip\\
Die Variable Name, die jedes Objekt gesetzt hat ist eine Identifizierung um Objekte ihren mutmaßlichen Vorkommen in der Messung zuzuordnen. Die Funktion EnthaeltObjektMitName(string Name) gibt true aus, falls die aufrufende Liste von Objekten ein Objekt mit dem gegebenen Namen enthält. Ansonsten wird false ausgegeben. \smallskip\\
Die Funktion FindeObjektMitName(string Name) gibt das Objekt aus der Liste zurück, welches den gegebenen Namen trägt. Falls kein Objekt mit dem gegebenen Namen existiert wird NULL zurückgegeben. BerechneObjektWahrscheinlichkeit(Objekt C, Objekt D, Objekt A, Objekt B) nimmt vier Objekte und berechnet die Positions- und Orientierungsunterschiede zwischen den Parametern C und D sowie zwischen A und B. Anschließend werden die Differenzen abgeglichen und basierend auf den Unterschieden eine Wahrscheinlichkeitsabschätzung zwischen 0 und 1 abgegeben, wobei 1 für "mit der Szene übereinstimmend" und 0 für "weit entfernt" steht. Auch die Komplette Funktion speichert am Ende eine Wahrscheinlichkeit zwischen 0 und 1. Sie wird nicht ausgegeben, da auf die eingespeicherte Wahrscheinlichkeit über eine andere Schnittstelle zugegriffen wird und der Algorithmus nur den Zweck erfüllt die Wahrscheinlichkeit zu berechnen.


\section{Wahrscheinlichkeitsabschätzung}

komplexer mathematischer formulieren\\
Vergleichsbasierte Erkennung erklären\\
Stochastische Richtigkeit beweisen\\


\begin{deprecated}
\cite{davis93}


\end{deprecated}
